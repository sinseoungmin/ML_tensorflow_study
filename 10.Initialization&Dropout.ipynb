{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import  LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./MNIST_data_csv/mnist_train.csv', header=None)\n",
    "df_test = pd.read_csv('./MNIST_data_csv/mnist_test.csv', header=None)\n",
    "\n",
    "train_list = list(df_train)\n",
    "test_list = list(df_test)\n",
    "\n",
    "train_images = df_train.iloc[:,1:].values\n",
    "test_images = df_test.iloc[:,1:].values\n",
    "\n",
    "lb1 = LabelBinarizer()\n",
    "lb2 = LabelBinarizer()\n",
    "train_labels = lb1.fit_transform(df_train.iloc[:,0].values)\n",
    "test_labels = lb2.fit_transform(df_test.iloc[:,0].values)\n",
    "\n",
    "mnist = {'train':{\n",
    "        'images':train_images,\n",
    "        'labels':train_labels},\n",
    "        'test':{\n",
    "        'images':test_images,\n",
    "        'labels':test_labels}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.71979\n",
      "0.6804\n",
      "20 0.543549\n",
      "40 0.453451\n",
      "60 0.414749\n",
      "80 0.391904\n",
      "100 0.376385\n",
      "0.9042\n",
      "120 0.364952\n",
      "140 0.356068\n",
      "160 0.348901\n",
      "180 0.342957\n",
      "200 0.337923\n",
      "0.911\n",
      "220 0.333583\n",
      "240 0.329792\n",
      "260 0.326441\n",
      "280 0.323451\n",
      "300 0.320759\n",
      "0.9143\n",
      "320 0.31832\n",
      "340 0.316094\n",
      "360 0.314052\n",
      "380 0.31217\n",
      "400 0.310427\n",
      "0.9179\n",
      "420 0.308806\n",
      "440 0.307294\n",
      "460 0.305879\n",
      "480 0.304549\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float', [None, 10])\n",
    "\n",
    "w = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# construct model\n",
    "activation = tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "\n",
    "# minimize cost\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(activation), reduction_indices=1)) # cross entropy\n",
    "l_r = 0.00001\n",
    "optimizer = tf.train.GradientDescentOptimizer(l_r).minimize(cost) # gradient descent\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_train = {x:mnist['train']['images'], y:mnist['train']['labels']}\n",
    "    feed_test = {x:mnist['test']['images'], y:mnist['test']['labels']}\n",
    "    \n",
    "    # training cycle\n",
    "    for step in range(501):\n",
    "        sess.run(optimizer, feed_dict=feed_train)\n",
    "        \n",
    "        if step%20==0:\n",
    "            print(step, sess.run(cost, feed_dict=feed_train))\n",
    "        if step%100==0:\n",
    "            correc_prediction = tf.equal(tf.arg_max(activation,1), tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correc_prediction, tf.float32))\n",
    "            print(sess.run(accuracy, feed_dict=feed_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN with initialization & dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Xavier initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs+n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0/ (n_inputs+n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 79.8873\n",
      "0.1402\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cc520c682d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[1;31m# training cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m501\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\userv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\userv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\userv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\userv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\userv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameter\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size =100\n",
    "display_step = 1\n",
    "\n",
    "# tf graph input\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float', [None, 10])\n",
    "\n",
    "\n",
    "# 기본 초기값\n",
    "# w1 = tf.Variable(tf.random_normal([784,256]))\n",
    "# w2 = tf.Variable(tf.random_normal([256,256]))\n",
    "# w3 = tf.Variable(tf.random_normal([256,10]))\n",
    "\n",
    "# Xavier initialization\n",
    "w1 = tf.get_variable('w1', shape=[784,256], initializer=xavier_init(784,256))\n",
    "w2 = tf.get_variable('w2', shape=[256,256], initializer=xavier_init(256,256))\n",
    "w3 = tf.get_variable('w3', shape=[256,128], initializer=xavier_init(256,128))\n",
    "w4 = tf.get_variable('w4', shape=[128,64], initializer=xavier_init(128,64))\n",
    "w5 = tf.get_variable('w5', shape=[64,10], initializer=xavier_init(64,10))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "b3 = tf.Variable(tf.random_normal([128]))\n",
    "b4 = tf.Variable(tf.random_normal([64]))\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "\n",
    "# 기본 모델\n",
    "# l1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "# l2 = tf.nn.relu(tf.matmul(l1,w2)+b2) # hidden layer with relu activation\n",
    "# hypothesis = tf.matmul(l2,w3)+b3 # no need to use softmax here\n",
    "\n",
    "# more deep & Dropout\n",
    "dropout_rate = tf.placeholder('float')\n",
    "_l1 = tf.nn.relu(tf.add(tf.matmul(x,w1),b1))\n",
    "l1 = tf.nn.dropout(_l1, dropout_rate)\n",
    "_l2 = tf.nn.relu(tf.add(tf.matmul(l1,w2),b2))\n",
    "l2 = tf.nn.dropout(_l2, dropout_rate)\n",
    "_l3 = tf.nn.relu(tf.add(tf.matmul(l2,w3),b3))\n",
    "l3 = tf.nn.dropout(_l3, dropout_rate)\n",
    "_l4 = tf.nn.relu(tf.add(tf.matmul(l3,w4),b4))\n",
    "l4 = tf.nn.dropout(_l4, dropout_rate)\n",
    "\n",
    "hypothesis = tf.add(tf.matmul(l4, w5),b5)\n",
    "\n",
    "\n",
    "# define cost & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis,y)) # softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_train = {x:mnist['train']['images'], y:mnist['train']['labels'], dropout_rate:0.7}\n",
    "    feed_test = {x:mnist['test']['images'], y:mnist['test']['labels'], dropout_rate:1}\n",
    "    \n",
    "    # training cycle\n",
    "    for step in range(501):\n",
    "        sess.run(optimizer, feed_dict=feed_train)\n",
    "        \n",
    "        if step%20==0:\n",
    "            print(step, sess.run(cost, feed_dict=feed_train))\n",
    "        if step%100==0:\n",
    "            correc_prediction = tf.equal(tf.arg_max(hypothesis,1), tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correc_prediction, tf.float32))\n",
    "            print(sess.run(accuracy, feed_dict=feed_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax vs Neural Nets for MNIST => 91.4% vs 94.4%\n",
    "- Xavier initialization: 97.8%\n",
    "- Deep Neural Nets and Dropout: 98%\n",
    "- Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
